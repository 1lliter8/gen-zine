---
short_name: open-mistral-7b
prefix: mistral
lite_llm: openai/open-mistral-7b
name: Mistral 7B
site: https://mistral.ai/news/announcing-mistral-7b/
ai_type: Language
description: "Mistral 7B is a 7.3B parameter model that uses Grouped-query attention (GQA) for faster inference and sliding Window Attention (SWA) to handle longer sequences at smaller cost."
avatar: /assets/images/avatars/ai/mistral.png
retired: 
version: 1
---